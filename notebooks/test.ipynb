{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\workspace\\VQA\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from config import  config\n",
    "from model.vqa_model import VQAModel\n",
    "from transformers import AutoTokenizer\n",
    "from training import VQADataCollatorForGeneration, tokenizer\n",
    "from model.processor import VQAProcessor\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\workspace\\VQA\\data_processor.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['question'] = [word_tokenize(text_normalize(x), format='text') for x in df['question']]\n",
      "d:\\workspace\\VQA\\data_processor.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['answer'] = [word_tokenize(text_normalize(str(x)), format='text') for x in df['answer']]\n"
     ]
    }
   ],
   "source": [
    "from data_processor import VQADataset\n",
    "from torchvision import transforms\n",
    "df_train = pd.read_csv(\"./dataset/csv/train_data.csv\")\n",
    "df_val = pd.read_csv(\"./dataset/csv/dev_data.csv\")\n",
    "df_test = pd.read_csv(\"./dataset/csv/test_data.csv\")\n",
    "transforms = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "train_dataset = VQADataset(dataframe=df_train.loc[:5], mode=\"train\", transform=transforms)\n",
    "# val_dataset = VQADataset(dataframe=df_val, mode=\"val\", transform=transforms)\n",
    "# test_dataset = VQADataset(dataframe=df_test, mode=\"test\", transform=transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[    0,   277,     8,    18,   298,   740,    40,  4235,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [    0,   277,     8,    18,   298,   740,    40, 38970,     2,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1],\n",
      "        [    0,   277,     8,    18,   298,   740,    40, 13947, 36954,     2,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "             1,     1]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base\")\n",
    "questions = [\"ai là người sáng lập ra facebook\", \"ai là người sáng lập ra google\", \"ai là người sáng lập ra microsoft\"]\n",
    "padding = \"max_length\"\n",
    "max_question_length = 32\n",
    "truncation = True\n",
    "return_tensors = \"pt\"\n",
    "\n",
    "output = tokenizer(\n",
    "    text=questions,\n",
    "    padding=padding,\n",
    "    max_length=max_question_length,\n",
    "    truncation=truncation,\n",
    "    return_tensors=return_tensors,\n",
    "    return_attention_mask=True,\n",
    ")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['biển ghi gì ?', 'có bao_nhiêu người đàn_ông ?']\n",
      "['ghi đường hồ chí_minh', 'có hai người đàn_ông']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pixel_values': tensor([[[[-0.9948, -0.9948, -0.9949,  ..., -0.9976, -0.9986, -0.9997],\n",
       "           [-0.9948, -0.9948, -0.9949,  ..., -0.9983, -0.9988, -0.9998],\n",
       "           [-0.9947, -0.9948, -0.9949,  ..., -0.9986, -0.9992, -0.9993],\n",
       "           ...,\n",
       "           [-0.9942, -0.9942, -0.9943,  ..., -0.9951, -0.9976, -0.9983],\n",
       "           [-0.9944, -0.9944, -0.9942,  ..., -0.9953, -0.9983, -0.9985],\n",
       "           [-0.9943, -0.9942, -0.9941,  ..., -0.9949, -0.9967, -0.9974]],\n",
       " \n",
       "          [[-0.9941, -0.9941, -0.9941,  ..., -0.9970, -0.9978, -0.9993],\n",
       "           [-0.9941, -0.9940, -0.9940,  ..., -0.9977, -0.9981, -0.9994],\n",
       "           [-0.9940, -0.9940, -0.9940,  ..., -0.9979, -0.9986, -0.9989],\n",
       "           ...,\n",
       "           [-0.9946, -0.9946, -0.9947,  ..., -0.9955, -0.9979, -0.9985],\n",
       "           [-0.9948, -0.9948, -0.9946,  ..., -0.9956, -0.9985, -0.9985],\n",
       "           [-0.9948, -0.9946, -0.9945,  ..., -0.9951, -0.9969, -0.9975]],\n",
       " \n",
       "          [[-0.9939, -0.9939, -0.9939,  ..., -0.9989, -0.9993, -0.9997],\n",
       "           [-0.9939, -0.9939, -0.9939,  ..., -0.9993, -0.9994, -0.9998],\n",
       "           [-0.9938, -0.9938, -0.9939,  ..., -0.9994, -0.9996, -0.9996],\n",
       "           ...,\n",
       "           [-0.9962, -0.9962, -0.9962,  ..., -0.9968, -0.9987, -0.9992],\n",
       "           [-0.9963, -0.9963, -0.9962,  ..., -0.9971, -0.9994, -0.9993],\n",
       "           [-0.9962, -0.9961, -0.9960,  ..., -0.9969, -0.9982, -0.9986]]],\n",
       " \n",
       " \n",
       "         [[[-0.9923, -0.9922, -0.9922,  ..., -0.9930, -0.9953, -0.9968],\n",
       "           [-0.9923, -0.9922, -0.9922,  ..., -0.9923, -0.9929, -0.9958],\n",
       "           [-0.9923, -0.9922, -0.9922,  ..., -0.9926, -0.9928, -0.9962],\n",
       "           ...,\n",
       "           [-0.9935, -0.9935, -0.9932,  ..., -0.9928, -0.9927, -0.9931],\n",
       "           [-0.9935, -0.9936, -0.9935,  ..., -0.9933, -0.9928, -0.9931],\n",
       "           [-0.9933, -0.9935, -0.9939,  ..., -0.9936, -0.9930, -0.9932]],\n",
       " \n",
       "          [[-0.9972, -0.9973, -0.9974,  ..., -0.9929, -0.9956, -0.9973],\n",
       "           [-0.9973, -0.9974, -0.9974,  ..., -0.9927, -0.9931, -0.9961],\n",
       "           [-0.9974, -0.9975, -0.9975,  ..., -0.9928, -0.9928, -0.9962],\n",
       "           ...,\n",
       "           [-0.9950, -0.9950, -0.9954,  ..., -0.9926, -0.9927, -0.9932],\n",
       "           [-0.9950, -0.9949, -0.9950,  ..., -0.9931, -0.9927, -0.9929],\n",
       "           [-0.9947, -0.9946, -0.9953,  ..., -0.9934, -0.9927, -0.9929]],\n",
       " \n",
       "          [[-0.9981, -0.9982, -0.9984,  ..., -0.9926, -0.9946, -0.9957],\n",
       "           [-0.9981, -0.9982, -0.9984,  ..., -0.9924, -0.9926, -0.9950],\n",
       "           [-0.9980, -0.9982, -0.9984,  ..., -0.9925, -0.9926, -0.9957],\n",
       "           ...,\n",
       "           [-0.9964, -0.9963, -0.9967,  ..., -0.9924, -0.9924, -0.9928],\n",
       "           [-0.9964, -0.9963, -0.9963,  ..., -0.9928, -0.9923, -0.9926],\n",
       "           [-0.9961, -0.9961, -0.9965,  ..., -0.9930, -0.9924, -0.9926]]]]),\n",
       " 'input_ids': tensor([[   0,  262,  701,  148,  114,    2,    1],\n",
       "         [   0,   10, 1823,   18,  651,  114,    2]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1]]),\n",
       " 'labels': tensor([[    0,   701,   109,  1005, 43647,  9534,     2],\n",
       "         [    0,    10,    82,    18,   651,     2,     1]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collator = VQADataCollatorForGeneration(processor=VQAProcessor())\n",
    "data_collator([train_dataset[0], train_dataset[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\workspace\\VQA\\model\\vqa_model.py:47: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  h_attn = F.softmax(h_attn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 50, 64001])\n",
      "torch.Size([16, 50])\n",
      "tensor(11.5250, grad_fn=<NllLoss2DBackward0>)\n"
     ]
    }
   ],
   "source": [
    "prediction, ans_tokens = model(image, question, answer)\n",
    "ans_tokens = ans_tokens.long()\n",
    "print(prediction.shape)\n",
    "print(ans_tokens.shape)\n",
    "\n",
    "\n",
    "loss = criterion(prediction.permute(0, 2, 1), ans_tokens)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.argmax(prediction, dim=2) == ans_tokens).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['họ đang đi mua_sắm trong siêu_thị', 'tỉnh thái_bình', 'có bốn người đang ở trong phòng', 'dùng cho dịch covid-19', 'cổng khu di_tích có ba lối vào', '7 700 đồng một ký', 'trên thành giếng có con_số 1554', 'trên bức tường có treo hai cái đèn_lồng', 'bán hàng', 'vì sếp tôi vừa đẹp_trai vừa tử_tế', 'dự_án khu dân_cư đông bình_dương đang triển_khai', 'bảng thông_báo san_nhượng mặt_bằng', 'một nhân_viên', 'màu đỏ và màu trắng', 'với một người phụ_nữ', 'nước_mắm này có truyền_thống trăm năm']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(config.text_model)\n",
    "\n",
    "ans_decode = tokenizer.batch_decode(ans_vocab, skip_special_tokens=True)\n",
    "print(ans_decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vqa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
